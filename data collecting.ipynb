{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'set_num': '6608-1', 'name': 'Tractor', 'year': 1982, 'theme_id': 67, 'num_parts': 21, 'set_img_url': 'https://cdn.rebrickable.com/media/sets/6608-1/9875.jpg', 'set_url': 'https://rebrickable.com/sets/6608-1/tractor/', 'last_modified_dt': '2021-07-04T18:43:10.903443Z'}\n"
     ]
    }
   ],
   "source": [
    "import rebrick\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "# Due to restrict of policy, the api key cannot be shared, and we stored it in a module that will not be submitted.\n",
    "from config import api_key\n",
    "\n",
    "# get set info\n",
    "response = rebrick.lego.get_set(6608)\n",
    "print(json.loads(response.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 0, 'next': None, 'previous': None, 'results': []}\n"
     ]
    }
   ],
   "source": [
    "rebrick.init(api_key)\n",
    "\n",
    "# get user partlists\n",
    "response = rebrick.users.get_partlists()\n",
    "print(json.loads(response.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def getLinks(url): \n",
    "    html_page = requests.get(url)\n",
    "    soup = BeautifulSoup(html_page.content, 'lxml')\n",
    "    \n",
    "    html = list(soup.children)[4] \n",
    "    nav = list(html.children)[5] \n",
    "    \n",
    "    # get all the links on the page\n",
    "    links = []\n",
    "    for link in nav.findAll('a', attrs={'href': re.compile(\"https://\")}):\n",
    "        links.append(link.get('href'))\n",
    "    \n",
    "    #get the links to download\n",
    "    downloads_list = []\n",
    "    for item in links:\n",
    "        if item[0:44] == 'https://cdn.rebrickable.com/media/downloads/' and item[-3:]!='zip':\n",
    "            print(item)\n",
    "            downloads_list.append(item)\n",
    "    print(\"We have\", len(downloads_list), \"links to download.\")\n",
    "    return downloads_list\n",
    "\n",
    "def fetch_files(_linklist,_path):\n",
    "    if not os.path.isdir(_path): \n",
    "        os.makedirs(_path)\n",
    "    for link in linklist:\n",
    "        download_file(link, _path)\n",
    "        \n",
    "def download_file(url, _path):\n",
    "    \n",
    "    \"\"\"function to download a file at a given url and to a given path\"\"\"\n",
    "    \n",
    "    # get the file url w/o the slug\n",
    "    r = re.compile('[?]') # https://stackoverflow.com/a/2175096/8971265\n",
    "    file_url = r.split(url)\n",
    "    print(\"file_url:\", file_url[0])\n",
    "    \n",
    "    # get the file name\n",
    "    r = re.compile('https://cdn.rebrickable.com/media/downloads/')\n",
    "    file_name = r.split(file_url[0])[1]\n",
    "    print(\"file_name:\", file_name)\n",
    "    \n",
    "    # define headers dictionary\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"}\n",
    "    \n",
    "    # download the files\n",
    "    print(\"Downloading:\", file_name)\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        with open(os.path.join(_path,file_name), 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    print(\"Unzipping:\", file_name, \"\\n\")\n",
    "    with gzip.open(os.path.join(_path, file_name), 'rb') as f_src: \n",
    "        with open(os.path.join(_path,file_name[:-3]), 'wb') as f_dst:\n",
    "            shutil.copyfileobj(f_src, f_dst)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cdn.rebrickable.com/media/downloads/themes.csv.gz?1708032730.676682\n",
      "https://cdn.rebrickable.com/media/downloads/colors.csv.gz?1708032730.820682\n",
      "https://cdn.rebrickable.com/media/downloads/part_categories.csv.gz?1708032730.9366822\n",
      "https://cdn.rebrickable.com/media/downloads/parts.csv.gz?1708032731.4806828\n",
      "https://cdn.rebrickable.com/media/downloads/part_relationships.csv.gz?1708032740.4846933\n",
      "https://cdn.rebrickable.com/media/downloads/elements.csv.gz?1708032731.9046834\n",
      "https://cdn.rebrickable.com/media/downloads/sets.csv.gz?1708032732.6446843\n",
      "https://cdn.rebrickable.com/media/downloads/minifigs.csv.gz?1708032733.0726848\n",
      "https://cdn.rebrickable.com/media/downloads/inventories.csv.gz?1708032732.1766837\n",
      "https://cdn.rebrickable.com/media/downloads/inventory_parts.csv.gz?1708032739.7366924\n",
      "https://cdn.rebrickable.com/media/downloads/inventory_sets.csv.gz?1708032739.9566927\n",
      "https://cdn.rebrickable.com/media/downloads/inventory_minifigs.csv.gz?1708032740.232693\n",
      "We have 12 links to download.\n"
     ]
    }
   ],
   "source": [
    "URL='https://rebrickable.com/downloads/'\n",
    "linklist = getLinks(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://cdn.rebrickable.com/media/downloads/themes.csv.gz',\n",
       " '1592816880.2813647']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the file_url construction\n",
    "r = re.compile('[?]') # https://stackoverflow.com/a/2175096/8971265\n",
    "file_url = r.split(\"https://cdn.rebrickable.com/media/downloads/themes.csv.gz?1592816880.2813647\")\n",
    "file_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'themes.csv.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = re.compile('https://cdn.rebrickable.com/media/downloads/')\n",
    "file_name = r.split(file_url[0])[1]\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_url: https://cdn.rebrickable.com/media/downloads/themes.csv.gz\n",
      "file_name: themes.csv.gz\n",
      "Downloading: themes.csv.gz\n",
      "Unzipping: themes.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/colors.csv.gz\n",
      "file_name: colors.csv.gz\n",
      "Downloading: colors.csv.gz\n",
      "Unzipping: colors.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/part_categories.csv.gz\n",
      "file_name: part_categories.csv.gz\n",
      "Downloading: part_categories.csv.gz\n",
      "Unzipping: part_categories.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/parts.csv.gz\n",
      "file_name: parts.csv.gz\n",
      "Downloading: parts.csv.gz\n",
      "Unzipping: parts.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/part_relationships.csv.gz\n",
      "file_name: part_relationships.csv.gz\n",
      "Downloading: part_relationships.csv.gz\n",
      "Unzipping: part_relationships.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/elements.csv.gz\n",
      "file_name: elements.csv.gz\n",
      "Downloading: elements.csv.gz\n",
      "Unzipping: elements.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/sets.csv.gz\n",
      "file_name: sets.csv.gz\n",
      "Downloading: sets.csv.gz\n",
      "Unzipping: sets.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/minifigs.csv.gz\n",
      "file_name: minifigs.csv.gz\n",
      "Downloading: minifigs.csv.gz\n",
      "Unzipping: minifigs.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/inventories.csv.gz\n",
      "file_name: inventories.csv.gz\n",
      "Downloading: inventories.csv.gz\n",
      "Unzipping: inventories.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/inventory_parts.csv.gz\n",
      "file_name: inventory_parts.csv.gz\n",
      "Downloading: inventory_parts.csv.gz\n",
      "Unzipping: inventory_parts.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/inventory_sets.csv.gz\n",
      "file_name: inventory_sets.csv.gz\n",
      "Downloading: inventory_sets.csv.gz\n",
      "Unzipping: inventory_sets.csv.gz \n",
      "\n",
      "file_url: https://cdn.rebrickable.com/media/downloads/inventory_minifigs.csv.gz\n",
      "file_name: inventory_minifigs.csv.gz\n",
      "Downloading: inventory_minifigs.csv.gz\n",
      "Unzipping: inventory_minifigs.csv.gz \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pass the folder name we want to create and save downloads in\n",
    "data_path = os.path.join(\"data\")\n",
    "\n",
    "# download the files to that folder\n",
    "fetch_files(linklist, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rebrick\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "# Due to restrict of policy, the api key cannot be shared, and we stored it in a module that will not be submitted.\n",
    "from config import api_key\n",
    "\n",
    "# get set info\n",
    "response = rebrick.lego.get_set(6608)\n",
    "print(json.loads(response.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_file_tree(starting_dir, indent=''):\n",
    "    if os.path.isdir(starting_dir):\n",
    "        print(indent + os.path.basename(starting_dir) + '/')\n",
    "        indent += '  '\n",
    "        for item in os.listdir(starting_dir):\n",
    "            item_path = os.path.join(starting_dir, item)\n",
    "            generate_file_tree(item_path, indent)\n",
    "    else:\n",
    "        print(indent + '|-- ' + os.path.basename(starting_dir))\n",
    "\n",
    "starting_directory = os.getcwd()\n",
    "\n",
    "generate_file_tree(starting_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebrick.init(api_key)\n",
    "\n",
    "# get user partlists\n",
    "response = rebrick.users.get_partlists()\n",
    "print(json.loads(response.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getLinks(url): \n",
    "    html_page = requests.get(url)\n",
    "    soup = BeautifulSoup(html_page.content, 'lxml')\n",
    "    \n",
    "    html = list(soup.children)[4] \n",
    "    nav = list(html.children)[5] \n",
    "    \n",
    "    # get all the links on the page\n",
    "    links = []\n",
    "    for link in nav.findAll('a', attrs={'href': re.compile(\"https://\")}):\n",
    "        links.append(link.get('href'))\n",
    "    \n",
    "    #get the links to download\n",
    "    downloads_list = []\n",
    "    for item in links:\n",
    "        if item[0:44] == 'https://cdn.rebrickable.com/media/downloads/' and item[-3:]!='zip':\n",
    "            print(item)\n",
    "            downloads_list.append(item)\n",
    "    print(\"We have\", len(downloads_list), \"links to download.\")\n",
    "    return downloads_list\n",
    "\n",
    "def fetch_files(_linklist,_path):\n",
    "    if not os.path.isdir(_path): \n",
    "        os.makedirs(_path)\n",
    "    for link in linklist:\n",
    "        download_file(link, _path)\n",
    "        \n",
    "def download_file(url, _path):\n",
    "    \n",
    "    \"\"\"function to download a file at a given url and to a given path\"\"\"\n",
    "    \n",
    "    # get the file url w/o the slug\n",
    "    r = re.compile('[?]') # https://stackoverflow.com/a/2175096/8971265\n",
    "    file_url = r.split(url)\n",
    "    print(\"file_url:\", file_url[0])\n",
    "    \n",
    "    # get the file name\n",
    "    r = re.compile('https://cdn.rebrickable.com/media/downloads/')\n",
    "    file_name = r.split(file_url[0])[1]\n",
    "    print(\"file_name:\", file_name)\n",
    "    \n",
    "    # define headers dictionary\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"}\n",
    "    \n",
    "    # download the files\n",
    "    print(\"Downloading:\", file_name)\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        with open(os.path.join(_path,file_name), 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    print(\"Unzipping:\", file_name, \"\\n\")\n",
    "    with gzip.open(os.path.join(_path, file_name), 'rb') as f_src: \n",
    "        with open(os.path.join(_path,file_name[:-3]), 'wb') as f_dst:\n",
    "            shutil.copyfileobj(f_src, f_dst)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL='https://rebrickable.com/downloads/'\n",
    "linklist = getLinks(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the file_url construction\n",
    "r = re.compile('[?]') # https://stackoverflow.com/a/2175096/8971265\n",
    "file_url = r.split(\"https://cdn.rebrickable.com/media/downloads/themes.csv.gz?1592816880.2813647\")\n",
    "file_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile('https://cdn.rebrickable.com/media/downloads/')\n",
    "file_name = r.split(file_url[0])[1]\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the folder name we want to create and save downloads in\n",
    "data_path = os.path.join(\"data\")\n",
    "\n",
    "# download the files to that folder\n",
    "fetch_files(linklist, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Read URLs from Excel file\n",
    "excel_file = 'sets_links.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Create CSV file and write header\n",
    "with open('output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['SetPricing', 'SetDetails', 'URL']\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Use the first column (index 0) as the URL\n",
    "            url = row[0]\n",
    "\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Your existing code to extract information from the webpage\n",
    "            setpricing_element = driver.find_element(By.CSS_SELECTOR, '.setpricing div.row:nth-of-type(2) div.col-xs-7')\n",
    "            setdetails_element = driver.find_element(By.CSS_SELECTOR, '.setdetails div:nth-of-type(1) div.col-xs-7')\n",
    "\n",
    "            value_setpricing = setpricing_element.text.strip() if setpricing_element else \"Not Found\"\n",
    "            value_setdetails = setdetails_element.text.strip() if setdetails_element else \"Not Found\"\n",
    "\n",
    "            # Write to CSV\n",
    "            csv_writer.writerow({'SetPricing': value_setpricing, 'SetDetails': value_setdetails, 'URL': url})\n",
    "\n",
    "            print(f\"Values for {url} successfully written to output.csv\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for {url}: {e}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The link files can be downloaded using this shared link:\n",
    "https://ucliveac-my.sharepoint.com/:x:/g/personal/hwa185_uclive_ac_nz/EcB5ZsZ-OKdAm5BGLNv9eXUBL7ewLZiZ5PpFpA7zPL5jYQ?rtime=MiPi23Yu3Eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
